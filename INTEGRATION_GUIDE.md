# MM SYSTEM - INTEGRATION GUIDE
## Phase 1 MVP - Complete Implementation

---

## üìã OVERVIEW

This document explains how to integrate the **5 new modules** into the main `app.py` (Tab 8).

### Module Stack:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MM_SCANNER_UI                          ‚îÇ  ‚Üê Streamlit UI (Tab 8)
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  MM_ORCHESTRATOR                        ‚îÇ  ‚Üê Pipeline coordinator
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  MM_DATA_INGESTION  ‚îÇ  MM_QUANT_ENGINE  ‚îÇ  ‚Üê Core processing
‚îÇ  MM_AI_LAYER        ‚îÇ  MM_MEMORY        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üì
   SQLite Database (mm_system.db)
```

---

## üîß IMPLEMENTATION CHECKLIST

### Step 1: Verify Files Created ‚úÖ

Files should exist in `max-pain-analysis-public/`:

```
‚úÖ SYSTEM_SPEC.md              (350 lines - specification)
‚úÖ mm_data_ingestion.py        (200 lines - data persistence)
‚úÖ mm_quant_engine.py          (350 lines - algorithms)
‚úÖ mm_ai_layer.py              (300 lines - narratives)
‚úÖ mm_memory.py                (400 lines - backtesting)
‚úÖ mm_orchestrator.py          (200 lines - coordinator)
‚úÖ mm_scanner_ui.py            (350 lines - streamlit UI)
```

Run verification:

```bash
cd max-pain-analysis-public
python -c "import mm_data_ingestion, mm_quant_engine, mm_ai_layer, mm_memory, mm_orchestrator; print('‚úÖ All modules importable')"
```

### Step 2: Update Requirements ‚úÖ

Add to `requirements.txt`:

```
# MM System (already present)
streamlit==1.40.2
pandas==2.2.0
numpy==1.26.4
scipy==1.14.0
requests==2.32.3

# Additional for MM (if needed)
# sqlite3  ‚Üí comes with Python
# logging  ‚Üí comes with Python
```

Run:

```bash
pip install -r requirements.txt
```

### Step 3: Integrate Tab 8 into app.py

In `app.py`, find Tab 8 (around line 7879):

```python
# CURRENT (to be replaced):
with tab8:
    st.markdown("## MM SCANNER - OLD")
    # ... old code ...
```

Replace with:

```python
# NEW (integrated):
from mm_scanner_ui import render_mm_scanner_tab

with tab8:
    render_mm_scanner_tab(tab8)
```

Or inline the UI directly:

```python
with tab8:
    from mm_scanner_ui import MMScannerUI
    ui = MMScannerUI()
    ui.render_tab()
```

### Step 4: Test the Pipeline

Create `test_pipeline.py`:

```python
#!/usr/bin/env python3

import sys
sys.path.insert(0, 'max-pain-analysis-public')

from mm_orchestrator import MMSystemOrchestrator
from mm_memory import MemorySystem

# Initialize
orch = MMSystemOrchestrator()
mem = MemorySystem()

# Test data (mock contracts)
mock_contracts = [
    {
        'strike': 590.0,
        'type': 'call',
        'oi': 45000,
        'volume': 2000,
        'bid': 2.50,
        'ask': 2.75,
        'delta': 0.65,
        'gamma': 0.008,
        'theta': -0.02,
        'vega': 0.85,
        'iv': 0.25
    },
    # ... more contracts
]

# Run full pipeline
brief = orch.analyze_ticker(
    ticker='SPY',
    contracts=mock_contracts,
    price=590.45,
    iv=0.25,
    expiration='2024-12-20'
)

print("‚úÖ Pipeline test passed!")
print(brief)
```

Run:

```bash
python test_pipeline.py
```

### Step 5: Database Initialization

The system auto-creates `mm_system.db` on first run.

Verify:

```bash
sqlite3 mm_system.db ".tables"
# Output should show: snapshots, contracts, computed_levels, outcomes, predictions, ticker_profiles, ...
```

---

## üìä ARCHITECTURE DETAILS

### Data Flow:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. DATA INPUT (from UI)                                          ‚îÇ
‚îÇ    - Ticker (SPY/QQQ/NVDA/TSLA)                                  ‚îÇ
‚îÇ    - Expiration date                                             ‚îÇ
‚îÇ    - Refresh trigger                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. FETCH LIVE DATA (Tradier API - to be integrated)              ‚îÇ
‚îÇ    - Options chain (all strikes/expirations)                     ‚îÇ
‚îÇ    - Current underlying price                                    ‚îÇ
‚îÇ    - IV term structure                                           ‚îÇ
‚îÇ    - Volume & OI per contract                                    ‚îÇ
‚îÇ    - Greeks (delta, gamma, theta, vega)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. DATA INGESTION (mm_data_ingestion.py)                         ‚îÇ
‚îÇ    - Parse contracts                                             ‚îÇ
‚îÇ    - Store snapshot in SQLite                                    ‚îÇ
‚îÇ    - Return snapshot_id for pipeline                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. QUANTITATIVE ANALYSIS (mm_quant_engine.py)                    ‚îÇ
‚îÇ    - Calculate GEX per strike                                    ‚îÇ
‚îÇ    - Detect call/put walls                                       ‚îÇ
‚îÇ    - Calculate pinning score                                     ‚îÇ
‚îÇ    - Classify market regime                                      ‚îÇ
‚îÇ    - Generate 3 target scenarios                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. AI LAYER - NARRATIVE (mm_ai_layer.py)                         ‚îÇ
‚îÇ    - Convert quant metrics ‚Üí human-readable brief                ‚îÇ
‚îÇ    - Template-based (no LLM hallucinations)                      ‚îÇ
‚îÇ    - Include wall interpretations                                ‚îÇ
‚îÇ    - Scenario descriptions                                       ‚îÇ
‚îÇ    - Risk identification                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. MEMORY & LEARNING (mm_memory.py)                              ‚îÇ
‚îÇ    - Store prediction for backtesting                            ‚îÇ
‚îÇ    - Retrieve historical ticker profile                          ‚îÇ
‚îÇ    - Calculate weight adjustments                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 7. DISPLAY (mm_scanner_ui.py / Streamlit)                        ‚îÇ
‚îÇ    - Metrics: GEX, IV, Put/Call Ratio                            ‚îÇ
‚îÇ    - Walls table (strike, OI, distance, strength)                ‚îÇ
‚îÇ    - Regime indicator                                            ‚îÇ
‚îÇ    - Target scenarios table                                      ‚îÇ
‚îÇ    - MM Brief (markdown)                                         ‚îÇ
‚îÇ    - Ticker profile (historical)                                 ‚îÇ
‚îÇ    - Backtesting summary                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ KEY ALGORITHMS

### 1. GEX (Gamma Exposure)

**Formula:**
```
GEX = Œ£(gamma * open_interest * price¬≤)
```

**Interpretation:**
- GEX > 0: Market is long gamma ‚Üí wants mean reversion
- GEX < 0: Market is short gamma ‚Üí trend risk

### 2. Wall Detection

**Algorithm:**
1. Find all strikes with high OI
2. Filter: OI > 1.5√ó average of nearby strikes
3. Call wall: highest OI above current price
4. Put wall: highest OI below current price
5. Classify strength: WEAK/MEDIUM/STRONG

### 3. Pinning Score

**Formula:**
```
Pinning Score = 
  (distance_factor √ó 0.4) + 
  (strength_factor √ó 0.3) + 
  (gamma_factor √ó 0.2) + 
  (historical_pin_rate √ó 0.1)
```

**Range:** 0-1 (probability of pinning at wall at expiration)

### 4. Regime Classification

**CHOP (Choppy):**
- Low ATR (< 30th percentile)
- Positive gamma (mean reversion)
- Price oscillating between walls

**TREND:**
- High ATR (> 70th percentile)
- Negative gamma (fragility)
- Breakout likely

**SQUEEZE:**
- Bollinger Bands tight
- IV low
- Vol expansion probable

### 5. Target Scenarios

**Scenario A (Bullish):**
- Entry: Current price
- Target: Call wall strike
- Stop: Put wall strike
- Probability: 0.4 if strong wall, 0.3 if medium

**Scenario B (Bearish):**
- Entry: Current price
- Target: Put wall strike
- Stop: Call wall strike
- Probability: 0.35 if strong, 0.25 if medium

**Scenario C (Mean Reversion):**
- Entry: Current price
- Target: Center between walls
- Duration: Based on regime
- Probability: 0.3

---

## üìà BACKTESTING WORKFLOW

### Storing Predictions:

```python
from mm_memory import MemorySystem

mem = MemorySystem()

# After analysis, store prediction
pred_id = mem.store_prediction(
    ticker='SPY',
    targets={'A': 595, 'B': 585, 'C': 590},
    call_wall=595.0,
    put_wall=585.0,
    regime='CHOP',
    pinning_score=0.68,
    expiration='2024-12-20',
    entry_price=590.45
)
```

### Recording Outcomes (later):

```python
# After the trade/day ends
mem.record_outcome(
    prediction_id=pred_id,
    ticker='SPY',
    actual_price=594.80,
    entry_price=590.45,
    target_hit='CALL_WALL',  # or 'PUT_WALL', 'CENTER', 'MISS'
    time_to_target=120,  # minutes
    regime_correct=True,
    wall_respected=True
)
```

### Getting Historical Profile:

```python
profile = mem.get_ticker_profile('SPY')
# Returns:
# {
#   'pin_hit_rate': 0.68,        # 68% accuracy on pinning predictions
#   'wall_respect_rate': 0.75,   # 75% of time walls acted as support/resistance
#   'vol_expansion_freq': 0.35,  # 35% of time vol expanded
#   'regime_accuracy': 0.62,     # 62% accuracy on regime calls
#   'sample_size': 42,           # based on 42 past predictions
#   'confidence': 0.42           # confidence in metrics (42/100)
# }
```

---

## üîó INTEGRATION WITH EXISTING CODE

### Current Tab 8 Location:

In `app.py`, find:

```python
# Line ~7879
with tab8:
    st.markdown("## MM SCANNER")
    # ... existing code for 230 lines ...
```

### Option A: Full Replacement (Recommended)

```python
# app.py (line 7879)
import sys
sys.path.insert(0, 'max-pain-analysis-public')

from mm_scanner_ui import MMScannerUI

# In tab8:
with tab8:
    ui = MMScannerUI()
    ui.render_tab()
```

### Option B: Hybrid (Keep some existing, add new)

Keep existing Tab 8 structure, import MM modules as needed:

```python
# app.py (line 7879)
with tab8:
    st.markdown("## MARKET MAKER ANALYSIS")
    
    # ... existing code ...
    
    # Add MM System below:
    with st.expander("üî¨ Advanced MM Analysis"):
        from mm_scanner_ui import MMScannerUI
        ui = MMScannerUI()
        ui.render_tab()
```

### Accessing Tradier API:

Replace mock data in `mm_scanner_ui.py`:

```python
# In _fetch_live_data() method:

import os
from requests import Session

tradier_session = Session()
tradier_session.headers.update({
    'Authorization': f'Bearer {os.getenv("TRADIER_API_TOKEN")}',
    'Accept': 'application/json'
})

# Fetch options chain
response = tradier_session.get(
    f'https://api.tradier.com/v1/markets/options/chains',
    params={'symbol': ticker, 'expiration': expiration}
)

if response.status_code == 200:
    chains_data = response.json()
    contracts = chains_data['options']['option']
    # Parse into structure expected by pipeline
```

---

## üêõ DEBUGGING

### Check Imports:

```bash
cd max-pain-analysis-public
python -c "from mm_orchestrator import MMSystemOrchestrator; print('‚úÖ OK')"
```

### Check Database:

```bash
sqlite3 mm_system.db
sqlite> SELECT name FROM sqlite_master WHERE type='table';
sqlite> SELECT COUNT(*) FROM snapshots;  # Should show number of stored snapshots
```

### Test Full Pipeline:

```python
from mm_orchestrator import MMSystemOrchestrator

orch = MMSystemOrchestrator()
brief = orch.analyze_ticker(
    ticker='SPY',
    contracts=[...],
    price=590.45,
    iv=0.25,
    expiration='2024-12-20'
)
print(brief)  # Should print professional MM Brief
```

### Common Issues:

| Issue | Solution |
|-------|----------|
| `ModuleNotFoundError` | Run `pip install -r requirements.txt` |
| Database locked | Close other connections, restart app |
| No contracts data | Mock data in UI for testing; implement real API integration |
| Import errors | Verify all 7 files exist in `max-pain-analysis-public/` |
| Slow first run | Database initialization takes ~2 seconds |

---

## üìÖ PHASE 2+ ROADMAP

After Phase 1 MVP is live:

### Phase 2: Quality Improvements (Week 2)
- [ ] Real Tradier API integration
- [ ] News sentiment integration (Google News API)
- [ ] Historical price fetching (Yahoo Finance)
- [ ] Better regime detection (CHOP indicator calculation)
- [ ] Custom Greeks calculation (Black-Scholes)

### Phase 3: Memory & Learning (Week 3)
- [ ] Dashboard for backtesting metrics by ticker
- [ ] Weight adjustment recommendations
- [ ] Regime accuracy tracking
- [ ] Wall respect analysis by market condition

### Phase 4: Production (Week 4)
- [ ] Real-time data streaming
- [ ] Alert system (Slack integration)
- [ ] Export to CSV/JSON
- [ ] Mobile-friendly UI
- [ ] SaaS deployment

---

## ‚úÖ VALIDATION CHECKLIST

Before deploying to production:

- [ ] All 7 modules import without errors
- [ ] Database created successfully (`mm_system.db`)
- [ ] Tab 8 renders in Streamlit
- [ ] Mock data pipeline completes end-to-end
- [ ] MM Brief output is professional-quality
- [ ] Historical profiles calculate correctly
- [ ] No crashes on rapid refreshes
- [ ] Git commits pushed successfully

---

## üìù NOTES

### Why 5 Modules?

1. **Data Ingestion**: Separate concern for persistence
2. **Quant Engine**: Pure math, testable, reusable
3. **AI Layer**: Converts metrics to narratives
4. **Memory**: Backtesting + learning system
5. **Orchestrator**: Coordinator, easy integration

This architecture allows:
- Unit testing of each component
- Easy swapping of algorithms
- Parallel development
- Clear data flow
- Institutional quality

### Next Immediate Tasks:

1. **Integrate into app.py** (15 min) ‚Üê START HERE
2. **Test with mock data** (30 min)
3. **Add real Tradier API** (2 hours)
4. **Backtest 100 predictions** (run overnight)
5. **Deploy to production** (30 min)

---

**Status**: Phase 1 MVP Complete ‚úÖ  
**Next**: Integration into app.py Tab 8  
**Timeline**: Implementation by [your deadline]
